{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cPickle as pkl\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdata, udata, data, users, repos = pkl.load(open('data_structuring_150.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actions': [u'IssueCommentEvent'],\n",
       "  'commits': 0,\n",
       "  'time_buckets': [9],\n",
       "  'times': [datetime.datetime(2015, 1, 26, 19, 5, 43)],\n",
       "  'user_is_owner': False},\n",
       " {'actions': [u'CommitCommentEvent', u'CommitCommentEvent'],\n",
       "  'commits': 0,\n",
       "  'time_buckets': [1, 1],\n",
       "  'times': [datetime.datetime(2015, 1, 1, 13, 17, 12),\n",
       "   datetime.datetime(2015, 1, 1, 13, 18, 4)],\n",
       "  'user_is_owner': False},\n",
       " {'actions': [u'PullRequestEvent'],\n",
       "  'commits': 0,\n",
       "  'time_buckets': [6],\n",
       "  'times': [datetime.datetime(2015, 1, 17, 4, 17, 44)],\n",
       "  'user_is_owner': False},\n",
       " {'actions': [u'IssuesEvent'],\n",
       "  'commits': 0,\n",
       "  'time_buckets': [6],\n",
       "  'times': [datetime.datetime(2015, 1, 16, 21, 5, 43)],\n",
       "  'user_is_owner': False},\n",
       " {'actions': [u'WatchEvent'],\n",
       "  'commits': 0,\n",
       "  'time_buckets': [2],\n",
       "  'times': [datetime.datetime(2015, 1, 6, 15, 44, 47)],\n",
       "  'user_is_owner': False}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encodings = {'MemberEvent': \"none\",\n",
    " 'PublicEvent': \"design\",\n",
    " 'PullRequestReviewCommentEvent': \"design\",\n",
    " 'ForkEvent': \"consume\",\n",
    " 'GollumEvent': \"design\",\n",
    " 'ReleaseEvent': \"none\",\n",
    " 'PullRequestEvent': \"content\",\n",
    " 'IssueCommentEvent': \"design\",\n",
    " 'PushEvent': \"content\",\n",
    " 'DeleteEvent': \"content\",\n",
    " 'CommitCommentEvent': \"design\",\n",
    " 'WatchEvent': \"consume\",\n",
    " 'IssuesEvent': \"design\",\n",
    " 'CreateEvent': \"content\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MIPnet():\n",
    "    def __init__(self, P, R, decay = 0.9):\n",
    "        self.P = P # partner\n",
    "        self.R = R # repos\n",
    "        self.mip = nx.MultiGraph()\n",
    "        self.mip.add_nodes_from(self.P, ntype=\"user\")\n",
    "        self.mip.add_nodes_from(self.R, ntype=\"repo\")\n",
    "        self.centrality = {}\n",
    "        self.decay = decay\n",
    "        \n",
    "        \n",
    "    # currently, user-user, repo-repo increase by max 1 in weight, \n",
    "    # could also be 1 per common edit\n",
    "    def update_edges_for_time(self,ints):\n",
    "        thisBucketUserRepos = defaultdict(set)\n",
    "        thisBucketRepoUsers = defaultdict(set)\n",
    "        # create or update user-repo edges and repo-repo edges\n",
    "        for ix,i in enumerate(ints):\n",
    "            cuser, crepo, ctype = i\n",
    "            # repo-repo: create/update edge if not exists in current time\n",
    "            if crepo not in thisBucketUserRepos[cuser] and len(thisBucketUserRepos[cuser]) > 0:\n",
    "                for connectRepo in thisBucketUserRepos[cuser]:\n",
    "                    if self.mip.has_edge(crepo, connectRepo):\n",
    "                        self.mip[crepo][connectRepo][0]['weight']+=1\n",
    "                    else:\n",
    "                        self.mip.add_edge(crepo, connectRepo, weight=1, ntype='r-r')\n",
    "            thisBucketUserRepos[cuser].add(crepo)\n",
    "\n",
    "            # user-user, similar to repo-repo\n",
    "            if cuser not in thisBucketRepoUsers[crepo] and len(thisBucketRepoUsers[crepo]) > 0:\n",
    "                for connectUser in thisBucketRepoUsers[crepo]:\n",
    "                    if self.mip.has_edge(cuser, connectUser):\n",
    "                        self.mip[cuser][connectUser][0]['weight']+=1\n",
    "                    else:\n",
    "                        self.mip.add_edge(cuser, connectUser, weight=1, ntype='u-u')\n",
    "            thisBucketRepoUsers[crepo].add(cuser)\n",
    "\n",
    "            # user-repo\n",
    "            edge_exists = False\n",
    "            # check whether edge exists\n",
    "            if (cuser, crepo, None) in self.mip.edges(cuser,crepo):\n",
    "                # if yes, iterate over edges to find whether the correct edge exists\n",
    "                for ednum,val in self.mip[cuser][crepo].iteritems():\n",
    "                    if val['ntype'] == ctype:\n",
    "                        edge_exists = True\n",
    "                        self.mip[cuser][crepo][ednum]['weight']+=1\n",
    "            if not edge_exists:\n",
    "                self.mip.add_edge(cuser, crepo, weight=1, ntype=ctype)\n",
    "        self.centrality = nx.degree_centrality(self.mip)\n",
    "                \n",
    "    def decay_weights(self):\n",
    "        for u,v,d in self.mip.edges(data=True):\n",
    "            d['weight'] = d['weight'] * self.decay\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_interactions_for_timebucket(t):\n",
    "    #creates a list of time\n",
    "    counter = 0\n",
    "    interactions = [] #user, repo, type\n",
    "    for ix,key in data.iteritems():\n",
    "        try: # there is one empty set in the data...\n",
    "            for time, types in zip(key['time_buckets'], key['actions']):\n",
    "                if time == t:\n",
    "                    if not label_encodings[types] == \"none\":\n",
    "                        interactions.append((ix[0], ix[1], label_encodings[types]))\n",
    "                #print types, time, \n",
    "            counter +=1\n",
    "#         if counter > 100:\n",
    "#             print interactions\n",
    "#             break\n",
    "        except:\n",
    "            pass \n",
    "    print \"found\", len(interactions), \"interactions\"\n",
    "    return interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 16194 interactions\n"
     ]
    }
   ],
   "source": [
    "# Simulate time steps\n",
    "mip = MIPnet(users, repos)\n",
    "interactions_bucket1 = get_all_interactions_for_timebucket(1)\n",
    "mip.update_edges_for_time(interactions_bucket1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 1\n",
      "found 16194 interactions\n",
      "34048 Edges between 26735 Nodes\n",
      "Bucket 2\n",
      "found 23973 interactions\n",
      "65740 Edges between 26735 Nodes\n",
      "Bucket 3\n",
      "found 31620 interactions\n",
      "95379 Edges between 26735 Nodes\n",
      "Bucket 4\n",
      "found 26499 interactions\n",
      "120711 Edges between 26735 Nodes\n",
      "Bucket 5\n",
      "found 38469 interactions\n",
      "172204 Edges between 26735 Nodes\n",
      "Bucket 6\n",
      "found 28763 interactions\n",
      "199121 Edges between 26735 Nodes\n",
      "Bucket 7\n",
      "found 26121 interactions\n",
      "226551 Edges between 26735 Nodes\n",
      "Bucket 8\n",
      "found 25313 interactions\n",
      "251684 Edges between 26735 Nodes\n",
      "Bucket 9\n",
      "found 19782 interactions\n",
      "271002 Edges between 26735 Nodes\n"
     ]
    }
   ],
   "source": [
    "# simulate all time buckets\n",
    "mip = MIPnet(users, repos)\n",
    "for i in range(1,10):\n",
    "    print \"Bucket\", i\n",
    "    mip.update_edges_for_time(get_all_interactions_for_timebucket(i))\n",
    "    print len(mip.mip.edges()), \"Edges between\", len(users)+len(repos), \"Nodes\"\n",
    "    mip.decay_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ntype': 'content', 'weight': 9.850707420300003}\n",
      "{'ntype': 'design', 'weight': 3.4480423521000008}\n",
      "{'ntype': 'consume', 'weight': 0.7791456501000001}\n"
     ]
    }
   ],
   "source": [
    "for ednum,val in mip.mip[\"Angelfirenze\"][\"deadlyvipers/dojo_rules\"].iteritems():\n",
    "    print val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [u'IssueCommentEvent'],\n",
       " 'commits': 0,\n",
       " 'time_buckets': [9],\n",
       " 'times': [datetime.datetime(2015, 1, 26, 19, 5, 43)],\n",
       " 'user_is_owner': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.keys()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Section\n",
    "\n",
    "### adjusted MIP-DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How much should each weight be worth? Start with equal\n",
    "params = {\"u-u\": 1,\n",
    "          \"r-r\": 1,\n",
    "          \"content\": 1,\n",
    "          \"design\": 1,\n",
    "          \"consume\": 1,}\n",
    "# Ofras parameters\n",
    "alpha = .5\n",
    "beta = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.76481103028371"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def connectionWeight(mip, n1,n2, gammas):\n",
    "    weight = 0.0\n",
    "    for ednum,val in mip[n1][n2].iteritems():\n",
    "        weight+= val['weight'] * gammas[val['ntype']]\n",
    "    return weight\n",
    "def adamicAdarProximity(mip, s, t, gammas):\n",
    "    proximity = 0.0\n",
    "    if (mip.has_node(s)==False) | (mip.has_node(t)==False):\n",
    "        return 0\n",
    "    for node in nx.common_neighbors(mip, s, t):\n",
    "        weights = connectionWeight(mip, s,node, gammas) + connectionWeight(mip, t,node, gammas)        \n",
    "        if weights!=0: # 0 essentially means no connection\n",
    "            # gives more weight to \"rare\" shared neighbors, adding small number to avoid dividing by zero\n",
    "            proximity = proximity + (weights*(1/(math.log(mip.degree(node, weight = 'weight'))+1e-9))) \n",
    "    return proximity\n",
    "adamicAdarProximity(mip.mip, \"Angelfirenze\", \"deadlyvipers/dojo_rules\", params)\n",
    "#TODO rescale both values or learn alpha/beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.623521370480484, 0.0005984888157402558, 13.246444252145228)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeDOI(mip, u, r, params):\n",
    "    # precomputed centrality + scaling factor\n",
    "    API = mip.centrality[r] #* 100\n",
    "    prox = adamicAdarProximity(mip.mip,u,r, params)\n",
    "    #print API, prox\n",
    "    return alpha * API + beta * prox, API, prox\n",
    "computeDOI(mip, \"Angelfirenze\", \"deadlyvipers/dojo_rules\", params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Predict interactions from only DOI vs. linear model using DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 22769 interactions\n"
     ]
    }
   ],
   "source": [
    "test_ints = get_all_interactions_for_timebucket(10)\n",
    "y_truths = Counter()\n",
    "for p in test_ints:\n",
    "    y_truths[(p[0],p[1])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for ix, u in enumerate(users):\n",
    "    #print udata[u]['repos']\n",
    "    current_list = []\n",
    "    for ix2, r in enumerate(repos):\n",
    "        doi, api, prox =  computeDOI(mip,u,r,params)\n",
    "        current_list.append((doi,r,api,prox))\n",
    "#         if ix2 > 20:\n",
    "#             break\n",
    "    current_list.sort()\n",
    "    for bla in current_list:#[-100:]:\n",
    "        X.append([bla[2], bla[3]])\n",
    "        Y.append(y_truths[(u,bla[1])])\n",
    "    if ix % 10 == 0:\n",
    "        print ix\n",
    "    if ix > 1000:\n",
    "        break\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00930668,  0.14293198]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X,Y)\n",
    "model.coef_#scores = cross_val_score(model, X, Y, cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = X[[Y==1]]\n",
    "neg = X[[Y==0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023245570593 0.000915582121361\n",
      "15.6097880635 0.01845092086\n"
     ]
    }
   ],
   "source": [
    "print pos[:,0].mean(), neg[:,0].mean()\n",
    "print pos[:,1].mean(), neg[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
